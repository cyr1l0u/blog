---
url: /2019/10/auto-mlag-and-auto-bgp-in-cumulus-linux.html
title: "Auto-MLAG and Auto-BGP in Cumulus Linux"
date: "2019-10-23T09:12:00.000+02:00"
tags: [ bridging,BGP ]
---

<p>When I first met Cumulus Networks engineers (<a href="https://blog.ipspace.net/2015/02/networking-field-day-9-brief-recap.html">during NFD9</a>) their focus on simplifying switch configurations <a href="https://blog.ipspace.net/2015/02/bgp-configuration-made-simple-with.html">totally delighted me</a> (<a href="https://blog.ipspace.net/2015/10/video-simplify-network-configurations.html">video</a>).</p>
<div class="note" data-markdown="1">I was <a href="https://blog.ipspace.net/2015/05/stupidities-of-switch-programming.html">ranting about the more traditional approach to data center fabric configuration</a> resulting in dozens if not hundreds of device configuration commands in 2013… and other vendors still haven't done much in this respect in the meantime. </div>
<p>After solving the BGP configuration challenge (could you imagine configuring BGP in a leaf-and-spine fabric with just a few commands in 2015), they did the same thing with EVPN configuration, where they decided to implement the simplest possible design (<a href="https://www.ipspace.net/Data_Center_BGP/BGP_in_EVPN-Based_Data_Center_Fabrics">EBGP-only fabric running EBGP EVPN sessions on leaf-to-spine links</a>), resulting in another round of configuration simplicity.<!--more--></p>
<div class="note" data-markdown="1">Of course you can always apply RFC 1925 Rule 6 and solve the same challenge by adding another layer of abstraction, this time using network automation with complex templates… but it turns out that the <a href="https://blog.ipspace.net/2017/08/challenges-of-data-center-fabric.html">state management needed to do that gets complex</a>, and your life becomes much easier if you don’t have to keep that state. </div>
<p>Fortunately Cumulus Networks didn’t decide to rest on the laurels - in the <a href="https://www.ipspace.net/Data_Center_Fabrics">Data Center Fabrics</a> update session we ran last week <a href="https://www.ipspace.net/Author:Pete_Lumbis">Pete Lumbis</a> talked about the new features they’re adding to Cumulus Linux 4.0 (<a href="https://my.ipspace.net/bin/list?id=DCFabric#CUMULUS">videos and slide deck</a>) - even more sane defaults, using auto-generated BGP AS numbers on leaf switches, and simplifying MLAG configuration (including peer link and server port channels) to a single command.</p>
<p>Here are a few more details Pete sent me:</p>
<hr/><p>With normal “product timeline planning is hard” caveats Auto BGP is planned for February, while Auto MLAG is a set of things, some already exist, including “<a href="https://docs.cumulusnetworks.com/cumulus-linux/Layer-2/Multi-Chassis-Link-Aggregation-MLAG/#configure-the-interfaces">MLAG unnumbered</a>” (expand the section “Cumulus Linux 3.7.7 and later”).  </p>
<p>The other interesting part of Auto MLAG is auto-bonding (turn a port receiving an LACP packet into a bond), which is also planned for February.</p>
<p>AutoBGP is not magic, we are effectively building a macro that will hash the platform MAC address and generate an ASN from the 4-byte private space. We are targeting two-tier Clos networks (Superspines are hard to solve for and those folks have opinions). To avoid further complexity we are planning on doing something along the lines of “net add bgp leaf” and “net add bgp spine”. If you say “spine” you get AS 4294967294. If you say “leaf” we hash against a search space of 4200000000 to 4294967293. I actually ran this against every <strong>cl-support</strong> (our “show tech”) we’ve ever collected and had zero ASN collisions. </p>
<p>For some of the MLAG features-</p>
<ul><li><strong>MLAG Unnumbered</strong> - This is the same as BGP unnumbered. The two MLAG peers need an L3 communication channel that is directly connected. Instead of assigning an IP address we just use the v6 LLA and discover our peer by listening for RAs on the defined bond interface.</li>
<li><strong>Auto Bonds</strong> - We haven’t decided if we will support this for non-MLAG scenarios, but with MLAG the idea is that when you receive an LACP packet you exchange all of that information with your MLAG peer as a “candidate bond member”. If the peer also sees these LACP messages we’ll just build a bond in kernel (i.e., “ip link add bond…”). This ends up eliminating ~6 lines of configuration for every server attached. </li>
<li><strong>Auto MLAG identifiers</strong> - Perhaps you still want to manually define bond ports and not just open up the world to sending you LACP messages. We can still make a life a bit easier by removing the need to define an MLAG bond identifier (Cisco uses “vpc 100” under the port channel for example) and just derive it from the received LACP messages. Auto Bonds would incorporate this.</li>
<li><strong>Logical MLAG Identifiers</strong> - Okay, you don’t want any of our fancy under the hood magic, you want to do everything the hard way. You have a strong desire to artisanally configure every bond on the system (or you’re unwilling to pay for a license to enable LACP on your unnamed hypervisor), we are adding the ability to provide strings as MLAG identifiers, for example “mlag-id mailServer01”.</li>
</ul>

